<?xml version="1.0" encoding="UTF-8"?>
<job>
  <name>pub_ods</name>
    <description/>
    <extended_description/>
    <job_version/>
    <job_status>0</job_status>
  <directory>&#x2f;</directory>
  <created_user>-</created_user>
  <created_date>2015&#x2f;09&#x2f;14 20&#x3a;05&#x3a;34.280</created_date>
  <modified_user>-</modified_user>
  <modified_date>2015&#x2f;09&#x2f;14 20&#x3a;05&#x3a;34.280</modified_date>
    <parameters>
        <parameter>
            <name>KETTLE_JOB_NAME</name>
            <default_value/>
            <description/>
        </parameter>
    </parameters>
  <connection>
    <name>hive</name>
    <server>&#x24;&#x7b;CMALDW_HIVE_DB_HOST&#x7d;</server>
    <type>HIVE2</type>
    <access>Native</access>
    <database>&#x24;&#x7b;CMALDW_HIVE_DB_NAME&#x7d;</database>
    <port>&#x24;&#x7b;CMALDW_HIVE_DB_PORT&#x7d;</port>
    <username>&#x24;&#x7b;CMALDW_HIVE_DB_USER&#x7d;</username>
    <password>&#x24;&#x7b;CMALDW_HIVE_DB_PASSWORD&#x7d;</password>
    <servername/>
    <data_tablespace/>
    <index_tablespace/>
    <attributes>
      <attribute><code>FORCE_IDENTIFIERS_TO_LOWERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>FORCE_IDENTIFIERS_TO_UPPERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>IS_CLUSTERED</code><attribute>N</attribute></attribute>
      <attribute><code>PORT_NUMBER</code><attribute>&#x24;&#x7b;CMALDW_HIVE_DB_PORT&#x7d;</attribute></attribute>
      <attribute><code>PRESERVE_RESERVED_WORD_CASE</code><attribute>Y</attribute></attribute>
      <attribute><code>QUOTE_ALL_FIELDS</code><attribute>N</attribute></attribute>
      <attribute><code>SUPPORTS_BOOLEAN_DATA_TYPE</code><attribute>Y</attribute></attribute>
      <attribute><code>SUPPORTS_TIMESTAMP_DATA_TYPE</code><attribute>Y</attribute></attribute>
      <attribute><code>USE_POOLING</code><attribute>N</attribute></attribute>
    </attributes>
  </connection>
    <slaveservers>
    </slaveservers>
<job-log-table><connection/>
<schema/>
<table/>
<size_limit_lines/>
<interval/>
<timeout_days/>
<field><id>ID_JOB</id><enabled>Y</enabled><name>ID_JOB</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>JOBNAME</id><enabled>Y</enabled><name>JOBNAME</name></field><field><id>STATUS</id><enabled>Y</enabled><name>STATUS</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>STARTDATE</id><enabled>Y</enabled><name>STARTDATE</name></field><field><id>ENDDATE</id><enabled>Y</enabled><name>ENDDATE</name></field><field><id>LOGDATE</id><enabled>Y</enabled><name>LOGDATE</name></field><field><id>DEPDATE</id><enabled>Y</enabled><name>DEPDATE</name></field><field><id>REPLAYDATE</id><enabled>Y</enabled><name>REPLAYDATE</name></field><field><id>LOG_FIELD</id><enabled>Y</enabled><name>LOG_FIELD</name></field><field><id>EXECUTING_SERVER</id><enabled>N</enabled><name>EXECUTING_SERVER</name></field><field><id>EXECUTING_USER</id><enabled>N</enabled><name>EXECUTING_USER</name></field><field><id>START_JOB_ENTRY</id><enabled>N</enabled><name>START_JOB_ENTRY</name></field><field><id>CLIENT</id><enabled>N</enabled><name>CLIENT</name></field></job-log-table>
<jobentry-log-table><connection/>
<schema/>
<table/>
<timeout_days/>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>JOBNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>JOBENTRYNAME</id><enabled>Y</enabled><name>STEPNAME</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>RESULT</id><enabled>Y</enabled><name>RESULT</name></field><field><id>NR_RESULT_ROWS</id><enabled>Y</enabled><name>NR_RESULT_ROWS</name></field><field><id>NR_RESULT_FILES</id><enabled>Y</enabled><name>NR_RESULT_FILES</name></field><field><id>LOG_FIELD</id><enabled>N</enabled><name>LOG_FIELD</name></field><field><id>COPY_NR</id><enabled>N</enabled><name>COPY_NR</name></field></jobentry-log-table>
<channel-log-table><connection/>
<schema/>
<table/>
<timeout_days/>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>LOGGING_OBJECT_TYPE</id><enabled>Y</enabled><name>LOGGING_OBJECT_TYPE</name></field><field><id>OBJECT_NAME</id><enabled>Y</enabled><name>OBJECT_NAME</name></field><field><id>OBJECT_COPY</id><enabled>Y</enabled><name>OBJECT_COPY</name></field><field><id>REPOSITORY_DIRECTORY</id><enabled>Y</enabled><name>REPOSITORY_DIRECTORY</name></field><field><id>FILENAME</id><enabled>Y</enabled><name>FILENAME</name></field><field><id>OBJECT_ID</id><enabled>Y</enabled><name>OBJECT_ID</name></field><field><id>OBJECT_REVISION</id><enabled>Y</enabled><name>OBJECT_REVISION</name></field><field><id>PARENT_CHANNEL_ID</id><enabled>Y</enabled><name>PARENT_CHANNEL_ID</name></field><field><id>ROOT_CHANNEL_ID</id><enabled>Y</enabled><name>ROOT_CHANNEL_ID</name></field></channel-log-table>
   <pass_batchid>N</pass_batchid>
   <shared_objects_file/>
  <entries>
    <entry>
      <name>START</name>
      <description/>
      <type>SPECIAL</type>
      <start>Y</start>
      <dummy>N</dummy>
      <repeat>N</repeat>
      <schedulerType>0</schedulerType>
      <intervalSeconds>0</intervalSeconds>
      <intervalMinutes>60</intervalMinutes>
      <hour>12</hour>
      <minutes>0</minutes>
      <weekDay>1</weekDay>
      <DayOfMonth>1</DayOfMonth>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>48</xloc>
      <yloc>48</yloc>
      </entry>
    <entry>
      <name>to_ods_inc_u_ora</name>
      <description/>
      <type>SQL</type>
      <sql>set hive.execution.engine &#x3d; &#x24;&#x7b;SET_ENGINE&#x7d;&#x3b;&#xd;&#xa;set mapreduce.job.queuename&#x3d;&#x24;&#x7b;CMALDW_ODS_QUEUE&#x7d;&#x3b;&#xd;&#xa;set spark.app.name &#x3d; &#x24;&#x7b;JOB_NAME&#x7d;&#x3b;&#xd;&#xa;set mapred.job.name &#x3d; &#x24;&#x7b;JOB_NAME&#x7d;&#x3b;&#xd;&#xa;&#xd;&#xa;INSERT OVERWRITE TABLE &#x24;&#x7b;TAR_ODS_TAB_NAME&#x7d;&#xd;&#xa;SELECT a.&#x2a; &#xd;&#xa;FROM &#x24;&#x7b;TAR_HIS_TAB_NAME&#x7d; a &#xd;&#xa;LEFT OUTER JOIN &#x24;&#x7b;TAR_STG_TAB_NAME&#x7d; b &#xd;&#xa;ON &#x24;&#x7b;JOIN_CONDITION&#x7d;&#xd;&#xa;WHERE b.&#x24;&#x7b;SPLIT_BY&#x7d; IS NULL&#xd;&#xa;&#x3b;&#xd;&#xa;&#xd;&#xa;INSERT INTO TABLE &#x24;&#x7b;TAR_ODS_TAB_NAME&#x7d;&#xd;&#xa;SELECT &#x2a; FROM &#x24;&#x7b;TAR_STG_TAB_NAME&#x7d;&#xd;&#xa;&#x3b;</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>hive</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>640</xloc>
      <yloc>176</yloc>
      </entry>
    <entry>
      <name>to_ods_all_ora</name>
      <description/>
      <type>SQL</type>
      <sql>set hive.execution.engine &#x3d; &#x24;&#x7b;SET_ENGINE&#x7d;&#x3b;&#xd;&#xa;set mapreduce.job.queuename&#x3d;&#x24;&#x7b;CMALDW_ODS_QUEUE&#x7d;&#x3b;&#xd;&#xa;set spark.app.name &#x3d; &#x24;&#x7b;JOB_NAME&#x7d;&#x3b;&#xd;&#xa;set mapred.job.name &#x3d; &#x24;&#x7b;JOB_NAME&#x7d;&#x3b;&#xd;&#xa;&#xd;&#xa;INSERT OVERWRITE TABLE &#x24;&#x7b;TAR_ODS_TAB_NAME&#x7d;&#xd;&#xa;SELECT &#x2a; FROM &#x24;&#x7b;TAR_STG_TAB_NAME&#x7d;&#xd;&#xa;&#x3b;</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>hive</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>640</xloc>
      <yloc>48</yloc>
      </entry>
    <entry>
      <name>to_his_inc_ora</name>
      <description/>
      <type>SQL</type>
      <sql>set hive.execution.engine &#x3d; &#x24;&#x7b;SET_ENGINE&#x7d;&#x3b;&#xd;&#xa;set mapreduce.job.queuename&#x3d;&#x24;&#x7b;CMALDW_ODS_QUEUE&#x7d;&#x3b;&#xd;&#xa;set spark.app.name &#x3d; &#x24;&#x7b;JOB_NAME&#x7d;&#x3b;&#xd;&#xa;set mapred.job.name &#x3d; &#x24;&#x7b;JOB_NAME&#x7d;&#x3b;&#xd;&#xa;&#xd;&#xa;INSERT OVERWRITE TABLE &#x24;&#x7b;TAR_HIS_TAB_NAME&#x7d;&#xd;&#xa;SELECT &#x2a; FROM &#x24;&#x7b;TAR_ODS_TAB_NAME&#x7d;&#xd;&#xa;&#x3b;</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>hive</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>832</xloc>
      <yloc>176</yloc>
      </entry>
    <entry>
      <name>to_ods_inc_i_ora</name>
      <description/>
      <type>SQL</type>
      <sql>set hive.execution.engine &#x3d; &#x24;&#x7b;SET_ENGINE&#x7d;&#x3b;&#xd;&#xa;set mapreduce.job.queuename&#x3d;&#x24;&#x7b;CMALDW_ODS_QUEUE&#x7d;&#x3b;&#xd;&#xa;set spark.app.name &#x3d; &#x24;&#x7b;JOB_NAME&#x7d;&#x3b;&#xd;&#xa;set mapred.job.name &#x3d; &#x24;&#x7b;JOB_NAME&#x7d;&#x3b;&#xd;&#xa;&#xd;&#xa;INSERT OVERWRITE TABLE &#x24;&#x7b;TAR_ODS_TAB_NAME&#x7d; PARTITION &#x28;PART_DT&#x3d;&#x27;&#x24;&#x7b;START_DATE&#x7d;&#x27;&#x29;&#xd;&#xa;SELECT &#x2a; FROM &#x24;&#x7b;TAR_STG_TAB_NAME&#x7d;&#xd;&#xa;&#x3b;</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>hive</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>640</xloc>
      <yloc>304</yloc>
      </entry>
    <entry>
      <name>update_para</name>
      <description/>
      <type>TRANS</type>
      <specification_method>filename</specification_method>
      <trans_object_id/>
      <filename>&#x24;&#x7b;CMALDW_ETL_PUBLIC&#x7d;&#x2f;ODS_AUTO&#x2f;public_update_parameter_ods.ktr</filename>
      <transname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>N</clear_rows>
      <clear_files>N</clear_files>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name/>
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <create_parent_folder>N</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>1024</xloc>
      <yloc>208</yloc>
      </entry>
    <entry>
      <name>get_para</name>
      <description/>
      <type>TRANS</type>
      <specification_method>filename</specification_method>
      <trans_object_id/>
      <filename>&#x24;&#x7b;CMALDW_ETL_PUBLIC&#x7d;&#x2f;ODS_AUTO&#x2f;public_generate_parameter_ods.ktr</filename>
      <transname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>N</clear_rows>
      <clear_files>N</clear_files>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name/>
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <create_parent_folder>N</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>144</xloc>
      <yloc>48</yloc>
      </entry>
    <entry>
      <name>check_extract_type_ora</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>&#x24;&#x7b;EXTRACT_MODE&#x7d;</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>0</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>startswith</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>256</xloc>
      <yloc>48</yloc>
      </entry>
    <entry>
      <name>check_inc_insert_type_ora</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>&#x24;&#x7b;EXTRACT_MODE&#x7d;</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>1</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>startswith</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>256</xloc>
      <yloc>176</yloc>
      </entry>
    <entry>
      <name>sqoop_inc_u_ora</name>
      <description/>
      <type>SHELL</type>
      <filename/>
      <work_directory>&#x24;&#x7b;CMALDW_WORKING_DIR&#x7d;</work_directory>
      <arg_from_previous>N</arg_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <set_append_logfile>N</set_append_logfile>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <insertScript>Y</insertScript>
      <script>sqoop import  -D mapreduce.job.queuename&#x3d;&#x24;&#x7b;CMALDW_ODS_QUEUE&#x7d;  --hive-import --where &#x22;&#x24;&#x7b;INCREMENT_FIELD&#x7d; &#x3e;&#x3d; to_date&#x28;&#x27;&#x24;&#x7b;START_DATE&#x7d;&#x27;, &#x27;yyyy-mm-dd&#x27;&#x29; AND &#x24;&#x7b;INCREMENT_FIELD&#x7d; &#x3c; to_date&#x28;&#x27;&#x24;&#x7b;END_DATE&#x7d;&#x27;, &#x27;yyyy-mm-dd&#x27;&#x29;&#x22;  --connect &#x24;&#x7b;DB_JDBC&#x7d;  --username &#x24;&#x7b;DB_USER&#x7d;  --password &#x24;&#x7b;DB_PASSWORD&#x7d; --table &#x24;&#x7b;SRC_TABLE_NAME&#x7d; --hive-table &#x24;&#x7b;TAR_STG_TAB_NAME&#x7d;  --delete-target-dir  --null-string &#x27;&#x5c;&#x5c;N&#x27;  --null-non-string &#x27;&#x5c;&#x5c;N&#x27;  --fields-terminated-by &#x24;&#x7b;TERMINATED_BY&#x7d;  --hive-delims-replacement &#x22;&#x22;  --hive-overwrite --split-by &#x24;&#x7b;SPLIT_BY&#x7d; -m &#x24;&#x7b;PARAR_NUM&#x7d;   --target-dir &#x2f;user&#x2f;hive&#x2f;temp&#x2f;&#x24;&#x7b;KETTLE_JOB_NAME&#x7d;  --fetch-size &#x24;&#x7b;FETCH_SIZE&#x7d;  --mapreduce-job-name &#x24;&#x7b;JOB_NAME&#x7d;</script>
      <loglevel>Basic</loglevel>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>432</xloc>
      <yloc>176</yloc>
      </entry>
    <entry>
      <name>sqoop_inc_i_ora</name>
      <description/>
      <type>SHELL</type>
      <filename/>
      <work_directory>&#x24;&#x7b;CMALDW_WORKING_DIR&#x7d;</work_directory>
      <arg_from_previous>N</arg_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <set_append_logfile>N</set_append_logfile>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <insertScript>Y</insertScript>
      <script>sqoop import -D mapreduce.job.queuename&#x3d;&#x24;&#x7b;CMALDW_ODS_QUEUE&#x7d;  --hive-import --where &#x22;&#x24;&#x7b;INCREMENT_FIELD&#x7d; &#x3e;&#x3d; to_date&#x28;&#x27;&#x24;&#x7b;START_DATE&#x7d;&#x27;, &#x27;yyyy-mm-dd&#x27;&#x29; AND &#x24;&#x7b;INCREMENT_FIELD&#x7d; &#x3c; to_date&#x28;&#x27;&#x24;&#x7b;END_DATE&#x7d;&#x27;, &#x27;yyyy-mm-dd&#x27;&#x29;&#x22;  --connect &#x24;&#x7b;DB_JDBC&#x7d;  --username &#x24;&#x7b;DB_USER&#x7d;  --password &#x24;&#x7b;DB_PASSWORD&#x7d; --table &#x24;&#x7b;SRC_TABLE_NAME&#x7d; --hive-table &#x24;&#x7b;TAR_STG_TAB_NAME&#x7d;  --delete-target-dir  --null-string &#x27;&#x5c;&#x5c;N&#x27;  --null-non-string &#x27;&#x5c;&#x5c;N&#x27;  --fields-terminated-by &#x24;&#x7b;TERMINATED_BY&#x7d;  --hive-delims-replacement &#x22;&#x22;  --hive-overwrite --split-by &#x24;&#x7b;SPLIT_BY&#x7d; -m &#x24;&#x7b;PARAR_NUM&#x7d;   --target-dir &#x2f;user&#x2f;hive&#x2f;temp&#x2f;&#x24;&#x7b;KETTLE_JOB_NAME&#x7d;   --fetch-size &#x24;&#x7b;FETCH_SIZE&#x7d;  --mapreduce-job-name &#x24;&#x7b;JOB_NAME&#x7d;</script>
      <loglevel>Basic</loglevel>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>432</xloc>
      <yloc>304</yloc>
      </entry>
    <entry>
      <name>sqoop_all_ora</name>
      <description/>
      <type>SHELL</type>
      <filename/>
      <work_directory>&#x24;&#x7b;CMALDW_WORKING_DIR&#x7d;</work_directory>
      <arg_from_previous>N</arg_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <set_append_logfile>N</set_append_logfile>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <insertScript>Y</insertScript>
      <script>sqoop import  -D mapreduce.job.queuename&#x3d;&#x24;&#x7b;CMALDW_ODS_QUEUE&#x7d;  --hive-import --connect &#x24;&#x7b;DB_JDBC&#x7d;  --username &#x24;&#x7b;DB_USER&#x7d;  --password &#x24;&#x7b;DB_PASSWORD&#x7d; --table &#x24;&#x7b;SRC_TABLE_NAME&#x7d; --hive-table &#x24;&#x7b;TAR_STG_TAB_NAME&#x7d;  --delete-target-dir  --null-string &#x27;&#x5c;&#x5c;N&#x27;  --null-non-string &#x27;&#x5c;&#x5c;N&#x27;  --fields-terminated-by &#x24;&#x7b;TERMINATED_BY&#x7d;  --hive-delims-replacement &#x22;&#x22;  --hive-overwrite --split-by &#x24;&#x7b;SPLIT_BY&#x7d; -m &#x24;&#x7b;PARAR_NUM&#x7d;   --target-dir &#x2f;user&#x2f;hive&#x2f;temp&#x2f;&#x24;&#x7b;KETTLE_JOB_NAME&#x7d;  --fetch-size &#x24;&#x7b;FETCH_SIZE&#x7d;  --mapreduce-job-name &#x24;&#x7b;JOB_NAME&#x7d;</script>
      <loglevel>Basic</loglevel>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>432</xloc>
      <yloc>48</yloc>
      </entry>
    <entry>
      <name>SUCCESS</name>
      <description/>
      <type>SUCCESS</type>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>1136</xloc>
      <yloc>208</yloc>
      </entry>
    <entry>
      <name>check_inc_insert_type_query</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>&#x24;&#x7b;EXTRACT_MODE&#x7d;</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>2</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>startswith</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>256</xloc>
      <yloc>304</yloc>
      </entry>
    <entry>
      <name>check_inc_query</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>&#x24;&#x7b;EXTRACT_MODE&#x7d;</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>3</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>startswith</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>256</xloc>
      <yloc>448</yloc>
      </entry>
    <entry>
      <name>sqoop_all_ora_query</name>
      <description/>
      <type>SHELL</type>
      <filename/>
      <work_directory>&#x24;&#x7b;CMALDW_WORKING_DIR&#x7d;</work_directory>
      <arg_from_previous>N</arg_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <set_append_logfile>N</set_append_logfile>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <insertScript>Y</insertScript>
      <script>sqoop import -D mapreduce.job.queuename&#x3d;&#x24;&#x7b;CMALDW_ODS_QUEUE&#x7d;  --hive-import --connect &#x24;&#x7b;DB_JDBC&#x7d;  --username &#x24;&#x7b;DB_USER&#x7d;  --password &#x24;&#x7b;DB_PASSWORD&#x7d; --query &#x24;&#x7b;QUERY_STATEMENT&#x7d; --hive-table &#x24;&#x7b;TAR_STG_TAB_NAME&#x7d;  --delete-target-dir  --null-string &#x27;&#x5c;&#x5c;N&#x27;  --null-non-string &#x27;&#x5c;&#x5c;N&#x27;  --fields-terminated-by &#x24;&#x7b;TERMINATED_BY&#x7d;  --hive-delims-replacement &#x22;&#x22;  --hive-overwrite --split-by &#x24;&#x7b;SPLIT_BY&#x7d; -m &#x24;&#x7b;PARAR_NUM&#x7d;   --target-dir &#x2f;user&#x2f;hive&#x2f;temp&#x2f;&#x24;&#x7b;KETTLE_JOB_NAME&#x7d;   --fetch-size &#x24;&#x7b;FETCH_SIZE&#x7d;  --mapreduce-job-name &#x24;&#x7b;JOB_NAME&#x7d;</script>
      <loglevel>Basic</loglevel>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>432</xloc>
      <yloc>384</yloc>
      </entry>
    <entry>
      <name>to_ods_all_ora_query</name>
      <description/>
      <type>SQL</type>
      <sql>set hive.execution.engine &#x3d; &#x24;&#x7b;SET_ENGINE&#x7d;&#x3b;&#xd;&#xa;set mapreduce.job.queuename&#x3d;&#x24;&#x7b;CMALDW_ODS_QUEUE&#x7d;&#x3b;&#xd;&#xa;set spark.app.name &#x3d; &#x24;&#x7b;JOB_NAME&#x7d;&#x3b;&#xd;&#xa;set mapred.job.name &#x3d; &#x24;&#x7b;JOB_NAME&#x7d;&#x3b;&#xd;&#xa;&#xd;&#xa;INSERT OVERWRITE TABLE &#x24;&#x7b;TAR_ODS_TAB_NAME&#x7d;&#xd;&#xa;SELECT &#x2a; FROM &#x24;&#x7b;TAR_STG_TAB_NAME&#x7d;&#xd;&#xa;&#x3b;</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>hive</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>640</xloc>
      <yloc>384</yloc>
      </entry>
    <entry>
      <name>to_ods_inc_u_ora_query</name>
      <description/>
      <type>SQL</type>
      <sql>set hive.execution.engine &#x3d; &#x24;&#x7b;SET_ENGINE&#x7d;&#x3b;&#xd;&#xa;set mapreduce.job.queuename&#x3d;&#x24;&#x7b;CMALDW_ODS_QUEUE&#x7d;&#x3b;&#xd;&#xa;set spark.app.name &#x3d; &#x24;&#x7b;JOB_NAME&#x7d;&#x3b;&#xd;&#xa;set mapred.job.name &#x3d; &#x24;&#x7b;JOB_NAME&#x7d;&#x3b;&#xd;&#xa;&#xd;&#xa;INSERT OVERWRITE TABLE &#x24;&#x7b;TAR_ODS_TAB_NAME&#x7d;&#xd;&#xa;SELECT a.&#x2a; &#xd;&#xa;FROM &#x24;&#x7b;TAR_HIS_TAB_NAME&#x7d; a &#xd;&#xa;LEFT OUTER JOIN &#x24;&#x7b;TAR_STG_TAB_NAME&#x7d; b &#xd;&#xa;ON &#x24;&#x7b;JOIN_CONDITION&#x7d;&#xd;&#xa;WHERE b.&#x24;&#x7b;SPLIT_BY&#x7d; IS NULL&#xd;&#xa;&#x3b;&#xd;&#xa;&#xd;&#xa;INSERT INTO TABLE &#x24;&#x7b;TAR_ODS_TAB_NAME&#x7d;&#xd;&#xa;SELECT &#x2a; FROM &#x24;&#x7b;TAR_STG_TAB_NAME&#x7d;&#xd;&#xa;&#x3b;</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>hive</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>640</xloc>
      <yloc>464</yloc>
      </entry>
    <entry>
      <name>to_his_inc_ora_query</name>
      <description/>
      <type>SQL</type>
      <sql>set hive.execution.engine &#x3d; &#x24;&#x7b;SET_ENGINE&#x7d;&#x3b;&#xd;&#xa;set mapreduce.job.queuename&#x3d;&#x24;&#x7b;CMALDW_ODS_QUEUE&#x7d;&#x3b;&#xd;&#xa;set spark.app.name &#x3d; &#x24;&#x7b;JOB_NAME&#x7d;&#x3b;&#xd;&#xa;set mapred.job.name &#x3d; &#x24;&#x7b;JOB_NAME&#x7d;&#x3b;&#xd;&#xa;&#xd;&#xa;INSERT OVERWRITE TABLE &#x24;&#x7b;TAR_HIS_TAB_NAME&#x7d;&#xd;&#xa;SELECT &#x2a; FROM &#x24;&#x7b;TAR_ODS_TAB_NAME&#x7d;&#xd;&#xa;&#x3b;</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>hive</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>832</xloc>
      <yloc>464</yloc>
      </entry>
    <entry>
      <name>sqoop_inc_u_ora_query</name>
      <description/>
      <type>SHELL</type>
      <filename/>
      <work_directory>&#x24;&#x7b;CMALDW_WORKING_DIR&#x7d;</work_directory>
      <arg_from_previous>N</arg_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <set_append_logfile>N</set_append_logfile>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <insertScript>Y</insertScript>
      <script>if &#x5b; &#x24;&#x7b;SRC_DB_TYPE&#x7d;x &#x3d; &#x22;SQLSERVER&#x22;x &#x5d;&#x3b; then&#xd;&#xa;&#x23;sqoop import  --hive-import --where &#x22;&#x24;&#x7b;INCREMENT_FIELD&#x7d; &#x3e;&#x3d; cast&#x28;&#x27;&#x24;&#x7b;START_DATE&#x7d;&#x27; as datetime&#x29; AND &#x24;&#x7b;INCREMENT_FIELD&#x7d; &#x3c; cast&#x28;&#x27;&#x24;&#x7b;END_DATE&#x7d;&#x27; as datetime&#x29;&#x22;  --connect &#x24;&#x7b;DB_JDBC&#x7d;  --username &#x24;&#x7b;DB_USER&#x7d;  --password &#x24;&#x7b;DB_PASSWORD&#x7d; --query &#x27;&#x24;&#x7b;QUERY_STATEMENT&#x7d;&#x27; --hive-table &#x24;&#x7b;TAR_STG_TAB_NAME&#x7d;  --delete-target-dir  --null-string &#x27;&#x5c;&#x5c;N&#x27;  --null-non-string &#x27;&#x5c;&#x5c;N&#x27;  --fields-terminated-by &#x24;&#x7b;TERMINATED_BY&#x7d;  --hive-delims-replacement &#x22;&#x22;  --hive-overwrite --split-by &#x24;&#x7b;SPLIT_BY&#x7d; -m &#x24;&#x7b;PARAR_NUM&#x7d;   --target-dir &#x2f;user&#x2f;hive&#x2f;temp&#x2f;&#x24;&#x7b;KETTLE_JOB_NAME&#x7d;  --fetch-size &#x24;&#x7b;FETCH_SIZE&#x7d;  --mapreduce-job-name &#x24;&#x7b;JOB_NAME&#x7d;&#xd;&#xa;sqoop import -D mapreduce.job.queuename&#x3d;&#x24;&#x7b;CMALDW_ODS_QUEUE&#x7d; --hive-import --connect &#x24;&#x7b;DB_JDBC&#x7d;  --username &#x24;&#x7b;DB_USER&#x7d;  --password &#x24;&#x7b;DB_PASSWORD&#x7d; --query &#x22;&#x24;&#x7b;QUERY_STATEMENT&#x7d; AND &#x24;&#x7b;INCREMENT_FIELD&#x7d; &#x3e;&#x3d; cast&#x28;&#x27;&#x24;&#x7b;START_DATE&#x7d;&#x27; as datetime&#x29; AND &#x24;&#x7b;INCREMENT_FIELD&#x7d; &#x3c; cast&#x28;&#x27;&#x24;&#x7b;END_DATE&#x7d;&#x27; as datetime&#x29;&#x22; --hive-table &#x24;&#x7b;TAR_STG_TAB_NAME&#x7d;  --delete-target-dir  --null-string &#x27;&#x5c;&#x5c;N&#x27;  --null-non-string &#x27;&#x5c;&#x5c;N&#x27;  --fields-terminated-by &#x24;&#x7b;TERMINATED_BY&#x7d;  --hive-delims-replacement &#x22;&#x22;  --hive-overwrite --split-by &#x24;&#x7b;SPLIT_BY&#x7d; -m &#x24;&#x7b;PARAR_NUM&#x7d;   --target-dir &#x2f;user&#x2f;hive&#x2f;temp&#x2f;&#x24;&#x7b;KETTLE_JOB_NAME&#x7d;  --fetch-size &#x24;&#x7b;FETCH_SIZE&#x7d;  --mapreduce-job-name &#x24;&#x7b;JOB_NAME&#x7d;&#xd;&#xa;elif &#x5b; &#x24;&#x7b;SRC_DB_TYPE&#x7d;x &#x3d; &#x22;MYSQL&#x22;x &#x5d;&#x3b; then&#xd;&#xa;&#x23; Mysql&#xd;&#xa;&#x23;sqoop import  --hive-import --where &#x22;&#x24;&#x7b;INCREMENT_FIELD&#x7d; &#x3e;&#x3d; str_to_date&#x28;&#x27;&#x24;&#x7b;START_DATE&#x7d;&#x27;, &#x27;&#x25;Y-&#x25;m-&#x25;d&#x27;&#x29; AND &#x24;&#x7b;INCREMENT_FIELD&#x7d; &#x3c; str_to_date&#x28;&#x27;&#x24;&#x7b;END_DATE&#x7d;&#x27;, &#x27;&#x25;Y-&#x25;m-&#x25;d&#x27;&#x29;&#x22;  --connect &#x24;&#x7b;DB_JDBC&#x7d;  --username &#x24;&#x7b;DB_USER&#x7d;  --password &#x24;&#x7b;DB_PASSWORD&#x7d; --query &#x27;&#x24;&#x7b;QUERY_STATEMENT&#x7d;&#x27; --hive-table &#x24;&#x7b;TAR_STG_TAB_NAME&#x7d;  --delete-target-dir  --null-string &#x27;&#x5c;&#x5c;N&#x27;  --null-non-string &#x27;&#x5c;&#x5c;N&#x27;  --fields-terminated-by &#x24;&#x7b;TERMINATED_BY&#x7d;  --hive-delims-replacement &#x22;&#x22;  --hive-overwrite --split-by &#x24;&#x7b;SPLIT_BY&#x7d; -m &#x24;&#x7b;PARAR_NUM&#x7d;   --target-dir &#x2f;user&#x2f;hive&#x2f;temp&#x2f;&#x24;&#x7b;KETTLE_JOB_NAME&#x7d;  --fetch-size &#x24;&#x7b;FETCH_SIZE&#x7d;  --mapreduce-job-name &#x24;&#x7b;JOB_NAME&#x7d;&#xd;&#xa;sqoop import  -D mapreduce.job.queuename&#x3d;&#x24;&#x7b;CMALDW_ODS_QUEUE&#x7d; --hive-import --connect &#x24;&#x7b;DB_JDBC&#x7d;  --username &#x24;&#x7b;DB_USER&#x7d;  --password &#x24;&#x7b;DB_PASSWORD&#x7d; --query &#x22;&#x24;&#x7b;QUERY_STATEMENT&#x7d; AND &#x24;&#x7b;INCREMENT_FIELD&#x7d; &#x3e;&#x3d; str_to_date&#x28;&#x27;&#x24;&#x7b;START_DATE&#x7d;&#x27;, &#x27;&#x25;Y-&#x25;m-&#x25;d&#x27;&#x29; AND &#x24;&#x7b;INCREMENT_FIELD&#x7d; &#x3c; str_to_date&#x28;&#x27;&#x24;&#x7b;END_DATE&#x7d;&#x27;, &#x27;&#x25;Y-&#x25;m-&#x25;d&#x27;&#x29;&#x22; --hive-table &#x24;&#x7b;TAR_STG_TAB_NAME&#x7d;  --delete-target-dir  --null-string &#x27;&#x5c;&#x5c;N&#x27;  --null-non-string &#x27;&#x5c;&#x5c;N&#x27;  --fields-terminated-by &#x24;&#x7b;TERMINATED_BY&#x7d;  --hive-delims-replacement &#x22;&#x22;  --hive-overwrite --split-by &#x24;&#x7b;SPLIT_BY&#x7d; -m &#x24;&#x7b;PARAR_NUM&#x7d;   --target-dir &#x2f;user&#x2f;hive&#x2f;temp&#x2f;&#x24;&#x7b;KETTLE_JOB_NAME&#x7d;  --fetch-size &#x24;&#x7b;FETCH_SIZE&#x7d;  --mapreduce-job-name &#x24;&#x7b;JOB_NAME&#x7d;&#xd;&#xa;else&#xd;&#xa;&#x23; Oracle &#xd;&#xa;sqoop import  -D mapreduce.job.queuename&#x3d;&#x24;&#x7b;CMALDW_ODS_QUEUE&#x7d; --hive-import --connect &#x24;&#x7b;DB_JDBC&#x7d;  --username &#x24;&#x7b;DB_USER&#x7d;  --password &#x24;&#x7b;DB_PASSWORD&#x7d; --query &#x22;&#x24;&#x7b;QUERY_STATEMENT&#x7d; AND &#x24;&#x7b;INCREMENT_FIELD&#x7d; &#x3e;&#x3d; to_date&#x28;&#x27;&#x24;&#x7b;START_DATE&#x7d;&#x27;, &#x27;yyyy-mm-dd&#x27;&#x29; AND &#x24;&#x7b;INCREMENT_FIELD&#x7d; &#x3c; to_date&#x28;&#x27;&#x24;&#x7b;END_DATE&#x7d;&#x27;, &#x27;yyyy-mm-dd&#x27;&#x29;&#x22; --hive-table &#x24;&#x7b;TAR_STG_TAB_NAME&#x7d;  --delete-target-dir  --null-string &#x27;&#x5c;&#x5c;N&#x27;  --null-non-string &#x27;&#x5c;&#x5c;N&#x27;  --fields-terminated-by &#x24;&#x7b;TERMINATED_BY&#x7d;  --hive-delims-replacement &#x22;&#x22;  --hive-overwrite --split-by &#x24;&#x7b;SPLIT_BY&#x7d; -m &#x24;&#x7b;PARAR_NUM&#x7d;   --target-dir &#x2f;user&#x2f;hive&#x2f;temp&#x2f;&#x24;&#x7b;KETTLE_JOB_NAME&#x7d;  --fetch-size &#x24;&#x7b;FETCH_SIZE&#x7d;  --mapreduce-job-name &#x24;&#x7b;JOB_NAME&#x7d;&#xd;&#xa;fi</script>
      <loglevel>Basic</loglevel>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>432</xloc>
      <yloc>464</yloc>
      </entry>
    <entry>
      <name>check_extract_mode_4</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>&#x24;&#x7b;EXTRACT_MODE&#x7d;</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>4</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>startswith</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>432</xloc>
      <yloc>560</yloc>
      </entry>
    <entry>
      <name>sqoop_all_ora_dmp</name>
      <description/>
      <type>SHELL</type>
      <filename/>
      <work_directory>&#x24;&#x7b;CMALDW_WORKING_DIR&#x7d;</work_directory>
      <arg_from_previous>N</arg_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <set_append_logfile>N</set_append_logfile>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <insertScript>Y</insertScript>
      <script>sqoop import -D mapreduce.job.queuename&#x3d;&#x24;&#x7b;CMALDW_ODS_QUEUE&#x7d;  --hive-import --connect &#x24;&#x7b;DB_JDBC&#x7d;  --username &#x24;&#x7b;DB_USER&#x7d;  --password &#x24;&#x7b;DB_PASSWORD&#x7d; --table &#x24;&#x7b;SRC_TABLE_NAME&#x7d; --hive-table &#x24;&#x7b;TAR_STG_TAB_NAME&#x7d;  --delete-target-dir  --null-string &#x27;&#x5c;&#x5c;N&#x27;  --null-non-string &#x27;&#x5c;&#x5c;N&#x27;  --fields-terminated-by &#x24;&#x7b;TERMINATED_BY&#x7d;  --hive-delims-replacement &#x22;&#x22;  --hive-overwrite --split-by &#x24;&#x7b;SPLIT_BY&#x7d; -m &#x24;&#x7b;PARAR_NUM&#x7d;   --target-dir &#x24;&#x7b;TARGET_DIR&#x7d;   --fetch-size &#x24;&#x7b;FETCH_SIZE&#x7d;  --mapreduce-job-name &#x24;&#x7b;JOB_NAME&#x7d;</script>
      <loglevel>Basic</loglevel>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>832</xloc>
      <yloc>560</yloc>
      </entry>
    <entry>
      <name>check_table_if_exist</name>
      <description/>
      <type>TABLE_EXISTS</type>
      <tablename>&#x24;&#x7b;CMALDW_TAR_ODS_HIS_TABLE&#x7d;</tablename>
      <schemaname>&#x24;&#x7b;CMALDW_TAR_ODS_HIS_SCHEMA&#x7d;</schemaname>
      <connection>hive</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>832</xloc>
      <yloc>48</yloc>
      </entry>
    <entry>
      <name>to_his_all_init</name>
      <description/>
      <type>SQL</type>
      <sql>set hive.execution.engine &#x3d; &#x24;&#x7b;SET_ENGINE&#x7d;&#x3b;&#xd;&#xa;set mapreduce.job.queuename&#x3d;&#x24;&#x7b;CMALDW_ODS_QUEUE&#x7d;&#x3b;&#xd;&#xa;set spark.app.name &#x3d; &#x24;&#x7b;JOB_NAME&#x7d;&#x3b;&#xd;&#xa;set mapred.job.name &#x3d; &#x24;&#x7b;JOB_NAME&#x7d;&#x3b;&#xd;&#xa;&#xd;&#xa;INSERT OVERWRITE TABLE &#x24;&#x7b;TAR_HIS_TAB_NAME&#x7d;&#xd;&#xa;SELECT &#x2a; FROM &#x24;&#x7b;TAR_ODS_TAB_NAME&#x7d;&#xd;&#xa;&#x3b;</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>hive</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>1024</xloc>
      <yloc>48</yloc>
      </entry>
    <entry>
      <name>check_table_if_exist_3</name>
      <description/>
      <type>TABLE_EXISTS</type>
      <tablename>&#x24;&#x7b;CMALDW_TAR_ODS_HIS_TABLE&#x7d;</tablename>
      <schemaname>&#x24;&#x7b;CMALDW_TAR_ODS_HIS_SCHEMA&#x7d;</schemaname>
      <connection>hive</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>832</xloc>
      <yloc>384</yloc>
      </entry>
    <entry>
      <name>to_his_all_init_3</name>
      <description/>
      <type>SQL</type>
      <sql>set hive.execution.engine &#x3d; &#x24;&#x7b;SET_ENGINE&#x7d;&#x3b;&#xd;&#xa;set mapreduce.job.queuename&#x3d;&#x24;&#x7b;CMALDW_ODS_QUEUE&#x7d;&#x3b;&#xd;&#xa;set spark.app.name &#x3d; &#x24;&#x7b;JOB_NAME&#x7d;&#x3b;&#xd;&#xa;set mapred.job.name &#x3d; &#x24;&#x7b;JOB_NAME&#x7d;&#x3b;&#xd;&#xa;&#xd;&#xa;INSERT OVERWRITE TABLE &#x24;&#x7b;TAR_HIS_TAB_NAME&#x7d;&#xd;&#xa;SELECT &#x2a; FROM &#x24;&#x7b;TAR_ODS_TAB_NAME&#x7d;&#xd;&#xa;&#x3b;</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>hive</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>832</xloc>
      <yloc>304</yloc>
      </entry>
  </entries>
  <hops>
    <hop>
      <from>to_ods_inc_u_ora</from>
      <to>to_his_inc_ora</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>to_his_inc_ora</from>
      <to>update_para</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>to_ods_inc_i_ora</from>
      <to>update_para</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>START</from>
      <to>get_para</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>check_extract_type_ora</from>
      <to>check_inc_insert_type_ora</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>sqoop_inc_u_ora</from>
      <to>to_ods_inc_u_ora</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>check_inc_insert_type_ora</from>
      <to>sqoop_inc_u_ora</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>check_extract_type_ora</from>
      <to>sqoop_all_ora</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>sqoop_inc_i_ora</from>
      <to>to_ods_inc_i_ora</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>sqoop_all_ora</from>
      <to>to_ods_all_ora</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>update_para</from>
      <to>SUCCESS</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>get_para</from>
      <to>check_extract_type_ora</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>check_inc_insert_type_ora</from>
      <to>check_inc_insert_type_query</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>check_inc_insert_type_query</from>
      <to>sqoop_inc_i_ora</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>check_inc_insert_type_query</from>
      <to>check_inc_query</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>check_inc_query</from>
      <to>sqoop_all_ora_query</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>sqoop_all_ora_query</from>
      <to>to_ods_all_ora_query</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>sqoop_inc_u_ora_query</from>
      <to>to_ods_inc_u_ora_query</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>to_ods_inc_u_ora_query</from>
      <to>to_his_inc_ora_query</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>to_his_inc_ora_query</from>
      <to>update_para</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>check_inc_query</from>
      <to>check_extract_mode_4</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>check_extract_mode_4</from>
      <to>sqoop_inc_u_ora_query</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>check_extract_mode_4</from>
      <to>sqoop_all_ora_dmp</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>sqoop_all_ora_dmp</from>
      <to>update_para</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>to_ods_all_ora</from>
      <to>check_table_if_exist</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>check_table_if_exist</from>
      <to>update_para</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>check_table_if_exist</from>
      <to>to_his_all_init</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>to_his_all_init</from>
      <to>update_para</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>to_ods_all_ora_query</from>
      <to>check_table_if_exist_3</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>check_table_if_exist_3</from>
      <to>to_his_all_init_3</to>
      <from_nr>1</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>to_his_all_init_3</from>
      <to>update_para</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>check_table_if_exist_3</from>
      <to>update_para</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
  </hops>
  <notepads>
    <notepad>
      <note>&#x529f;&#x80fd;&#x8bf4;&#x660e;&#xff1a; ODS &#x516c;&#x7528;&#x8f6c;&#x6362;&#xa;&#x521b;&#x5efa;&#x65e5;&#x671f;&#xff1a; 2017-09-19&#xa;&#x5907;&#x3000;&#x3000;&#x6ce8;&#xff1a;&#xa;EXTRACT_MODE&#x503c;&#x4e3a;  &#xa;0     &#x5168;&#x91cf;              table&#x65b9;&#x5f0f;&#xa;1     &#x589e;&#x91cf;              table&#x65b9;&#x5f0f;&#xa;2     &#x589e;&#x91cf;&#xff08;&#x5206;&#x533a;&#x5b58;&#x50a8;&#xff09;   table&#x65b9;&#x5f0f;&#xa;3     &#x5168;&#x91cf;              query&#x65b9;&#x5f0f;&#xa;4     &#x589e;&#x91cf;              query&#x65b9;&#x5f0f;&#xa;5     &#x5168;&#x91cf;              &#x65e0;&#x5217;&#x683c;&#x5f0f;&#x6307;&#x5b9a;&#x65b9;&#x5f0f;&#xa;&#x4f7f;&#x7528;query&#x65b9;&#x5f0f;&#xff0c;&#x5728;sql&#x672b;&#x5c3e;&#x8981;&#x52a0;where &#x24;CONDITIONS&#xa;&#x793a;&#x4f8b;&#xff1a;&#xd;&#xa;select &#x2a; from ANY3YKT.ALLSCHEDULING&#xd;&#xa;where &#x24;CONDITIONS</note>
      <xloc>0</xloc>
      <yloc>624</yloc>
      <width>360</width>
      <heigth>220</heigth>
      <fontname>.Helvetica Neue DeskInterface</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
  </notepads>

</job>
